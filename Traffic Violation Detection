import cv2
import numpy as np
import pandas as pd
from collections import defaultdict, deque
import datetime
import os
import time
from ultralytics import YOLO  # Using Ultralytics YOLOv8 for better detection
import torch

class EnhancedTrafficViolationDetector:
    def __init__(self):
        # Check if GPU is available
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"Using device: {self.device}")
        
        # Load YOLOv8 model (more accurate than YOLOv3)
        self.model = YOLO('yolov8n.pt')  # Use yolov8s.pt or yolov8m.pt for better accuracy
        
        # Vehicle classes we're interested in (car, motorcycle, bus, truck)
        self.vehicle_classes = [2, 3, 5, 7]
        
        # For tracking vehicles across frames
        self.tracked_objects = {}
        self.object_id = 0
        self.max_disappeared = 10
        
        # For speed calculation
        self.speed_estimation_area = None
        self.pixels_per_meter = None
        self.fps = 30  # Will be calculated from video
        
        # For traffic light detection
        self.traffic_light_state = "unknown"
        self.traffic_light_roi = None
        
        # For lane detection
        self.lane_boundaries = []
        
        # Violation records
        self.violations = []
        self.violation_count = defaultdict(int)
        
        # Visualization settings
        self.colors = {
            'car': (0, 255, 0),
            'bus': (255, 0, 0),
            'truck': (0, 0, 255),
            'motorcycle': (255, 255, 0),
            'violation': (0, 0, 255),
            'speed': (255, 255, 255),
            'traffic_light': (0, 255, 255)
        }
        
        # Speed limit (km/h)
        self.speed_limit = 50
        
        # Frame processing metrics
        self.frame_count = 0
        self.processing_times = deque(maxlen=100)
        
    def set_speed_estimation_area(self, points):
        """Set the area where speed will be calculated (4 points for perspective transform)"""
        self.speed_estimation_area = np.array(points, dtype=np.float32)
        
        # Calculate pixels per meter (approximate)
        width = np.linalg.norm(points[0] - points[1])
        self.pixels_per_meter = width / 3.7  # Assuming lane width is 3.7 meters
        
    def set_traffic_light_roi(self, roi):
        """Set region of interest for traffic light detection"""
        self.traffic_light_roi = roi
        
    def set_lane_boundaries(self, boundaries):
        """Set lane boundaries for violation detection"""
        self.lane_boundaries = boundaries
        
    def detect_vehicles(self, frame):
        """Detect vehicles in the frame using YOLOv8"""
        results = self.model(frame, verbose=False)
        
        detected_vehicles = []
        confidences = []
        class_ids = []
        
        for result in results:
            boxes = result.boxes
            for box in boxes:
                confidence = box.conf.item()
                class_id = int(box.cls.item())
                
                if confidence > 0.5 and class_id in self.vehicle_classes:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    w, h = x2 - x1, y2 - y1
                    detected_vehicles.append((int(x1), int(y1), int(w), int(h)))
                    confidences.append(confidence)
                    class_ids.append(class_id)
                    
        return detected_vehicles, confidences, class_ids
    
    def update_tracking(self, detections, confidences, class_ids):
        """Update object tracking with new detections using improved matching"""
        current_objects = {}
        
        # If no detections, mark all objects as disappeared
        if not detections:
            for obj_id in list(self.tracked_objects.keys()):
                self.tracked_objects[obj_id]['disappeared'] += 1
                if self.tracked_objects[obj_id]['disappeared'] > self.max_disappeared:
                    del self.tracked_objects[obj_id]
                else:
                    current_objects[obj_id] = self.tracked_objects[obj_id]
            return current_objects
        
        # Create cost matrix for Hungarian algorithm
        cost_matrix = np.zeros((len(self.tracked_objects), len(detections)))
        obj_ids = list(self.tracked_objects.keys())
        
        for i, obj_id in enumerate(obj_ids):
            obj_data = self.tracked_objects[obj_id]
            last_centroid = obj_data['centroids'][-1] if obj_data['centroids'] else (0, 0)
            
            for j, (x, y, w, h) in enumerate(detections):
                centroid = (x + w/2, y + h/2)
                distance = np.sqrt((centroid[0] - last_centroid[0])**2 + 
                                  (centroid[1] - last_centroid[1])**2)
                cost_matrix[i, j] = distance
        
        # Use Hungarian algorithm for optimal assignment
        if cost_matrix.size > 0:
            row_ind, col_ind = self.hungarian_algorithm(cost_matrix)
            
            # Process assignments
            assigned_detections = set()
            assigned_objects = set()
            
            for i, j in zip(row_ind, col_ind):
                if cost_matrix[i, j] < 100:  # Maximum allowed distance
                    obj_id = obj_ids[i]
                    x, y, w, h = detections[j]
                    centroid = (x + w/2, y + h/2)
                    
                    # Update existing object
                    self.tracked_objects[obj_id]['centroids'].append(centroid)
                    self.tracked_objects[obj_id]['rect'] = (x, y, w, h)
                    self.tracked_objects[obj_id]['disappeared'] = 0
                    self.tracked_objects[obj_id]['class_id'] = class_ids[j]
                    self.tracked_objects[obj_id]['confidence'] = confidences[j]
                    
                    current_objects[obj_id] = self.tracked_objects[obj_id]
                    assigned_detections.add(j)
                    assigned_objects.add(i)
        
        # Create new objects for unassigned detections
        for j in range(len(detections)):
            if j not in assigned_detections:
                self.object_id += 1
                x, y, w, h = detections[j]
                centroid = (x + w/2, y + h/2)
                
                self.tracked_objects[self.object_id] = {
                    'centroids': [centroid],
                    'rect': (x, y, w, h),
                    'disappeared': 0,
                    'first_seen': datetime.datetime.now(),
                    'speed': 0,
                    'class_id': class_ids[j],
                    'confidence': confidences[j],
                    'speed_history': deque(maxlen=10),
                    'last_violation': None
                }
                current_objects[self.object_id] = self.tracked_objects[self.object_id]
        
        # Handle disappeared objects
        for i, obj_id in enumerate(obj_ids):
            if i not in assigned_objects:
                self.tracked_objects[obj_id]['disappeared'] += 1
                if self.tracked_objects[obj_id]['disappeared'] > self.max_disappeared:
                    del self.tracked_objects[obj_id]
                else:
                    current_objects[obj_id] = self.tracked_objects[obj_id]
            
        return current_objects
    
    def hungarian_algorithm(self, cost_matrix):
        """Implementation of the Hungarian algorithm for assignment"""
        # Simple implementation - in production, use scipy.optimize.linear_sum_assignment
        n, m = cost_matrix.shape
        assignments = []
        
        if n <= m:
            for i in range(n):
                j = np.argmin(cost_matrix[i])
                assignments.append((i, j))
        else:
            for j in range(m):
                i = np.argmin(cost_matrix[:, j])
                assignments.append((i, j))
                
        row_ind = [a[0] for a in assignments]
        col_ind = [a[1] for a in assignments]
        
        return row_ind, col_ind
    
    def calculate_speed(self, obj_id, obj_data):
        """Calculate speed of a vehicle with improved accuracy"""
        if len(obj_data['centroids']) < 2:
            return 0
            
        # Get multiple centroids for more accurate speed calculation
        num_points = min(5, len(obj_data['centroids']))
        centroids = obj_data['centroids'][-num_points:]
        
        # Calculate distance traveled
        total_distance = 0
        for i in range(1, len(centroids)):
            c1 = centroids[i-1]
            c2 = centroids[i]
            pixel_distance = np.sqrt((c2[0] - c1[0])**2 + (c2[1] - c1[1])**2)
            total_distance += pixel_distance
        
        # Average distance per frame
        avg_pixel_distance = total_distance / (len(centroids) - 1)
        
        # Convert to meters
        distance_meters = avg_pixel_distance / self.pixels_per_meter
        
        # Calculate speed (distance / time)
        speed_mps = distance_meters * self.fps  # Meters per second
        
        # Convert to km/h
        speed_kmh = speed_mps * 3.6
        
        # Add to speed history
        obj_data['speed_history'].append(speed_kmh)
        
        # Use median of recent speeds for more stable reading
        if len(obj_data['speed_history']) > 0:
            speed_kmh = np.median(list(obj_data['speed_history']))
        
        return speed_kmh
    
    def detect_traffic_light(self, frame):
        """Detect traffic light state with improved accuracy"""
        if self.traffic_light_roi is None:
            return "unknown"
            
        x, y, w, h = self.traffic_light_roi
        light_roi = frame[y:y+h, x:x+w]
        
        if light_roi.size == 0:
            return "unknown"
        
        # Convert to HSV color space for better color detection
        hsv = cv2.cvtColor(light_roi, cv2.COLOR_BGR2HSV)
        
        # Define color ranges for traffic lights
        # Red color
        red_lower1 = np.array([0, 100, 100])
        red_upper1 = np.array([10, 255, 255])
        red_lower2 = np.array([160, 100, 100])
        red_upper2 = np.array([180, 255, 255])
        
        # Yellow color
        yellow_lower = np.array([20, 100, 100])
        yellow_upper = np.array([30, 255, 255])
        
        # Green color
        green_lower = np.array([40, 100, 100])
        green_upper = np.array([80, 255, 255])
        
        # Create masks for each color
        red_mask1 = cv2.inRange(hsv, red_lower1, red_upper1)
        red_mask2 = cv2.inRange(hsv, red_lower2, red_upper2)
        red_mask = cv2.bitwise_or(red_mask1, red_mask2)
        
        yellow_mask = cv2.inRange(hsv, yellow_lower, yellow_upper)
        green_mask = cv2.inRange(hsv, green_lower, green_upper)
        
        # Apply morphological operations to reduce noise
        kernel = np.ones((5, 5), np.uint8)
        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
        yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_CLOSE, kernel)
        green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)
        
        # Count non-zero pixels in each mask
        red_pixels = cv2.countNonZero(red_mask)
        yellow_pixels = cv2.countNonZero(yellow_mask)
        green_pixels = cv2.countNonZero(green_mask)
        
        # Determine the state based on which color has the most pixels
        max_pixels = max(red_pixels, yellow_pixels, green_pixels)
        
        if max_pixels < 100:  # Threshold to avoid false detections
            return "unknown"
        elif max_pixels == red_pixels:
            return "red"
        elif max_pixels == yellow_pixels:
            return "yellow"
        else:
            return "green"
    
    def detect_lane_violation(self, obj_data):
        """Check if a vehicle is crossing lane boundaries illegally"""
        if not self.lane_boundaries:
            return False
            
        centroid = obj_data['centroids'][-1]
        x, y, w, h = obj_data['rect']
        
        # Check if vehicle is crossing any lane boundary
        for boundary in self.lane_boundaries:
            if self.is_crossing_boundary((x, y, w, h), boundary, obj_data['centroids']):
                return True
                
        return False
    
    def is_crossing_boundary(self, bbox, boundary, centroids):
        """Check if a vehicle is crossing a lane boundary"""
        x, y, w, h = bbox
        (x1, y1), (x2, y2) = boundary
        
        # Check if vehicle is near the boundary
        vehicle_bottom_center = (x + w/2, y + h)
        
        # Calculate distance to line
        distance = self.point_to_line_distance(vehicle_bottom_center, (x1, y1), (x2, y2))
        
        # If vehicle is close to the line and moving across it
        if distance < 20 and len(centroids) > 1:
            # Check direction of movement
            prev_centroid = centroids[-2]
            curr_centroid = centroids[-1]
            
            # Check if vehicle is moving across the boundary
            prev_side = self.point_side_of_line(prev_centroid, (x1, y1), (x2, y2))
            curr_side = self.point_side_of_line(curr_centroid, (x1, y1), (x2, y2))
            
            if prev_side != curr_side:
                return True
                
        return False
    
    def point_to_line_distance(self, point, line_point1, line_point2):
        """Calculate distance from point to line"""
        x, y = point
        x1, y1 = line_point1
        x2, y2 = line_point2
        
        numerator = abs((y2-y1)*x - (x2-x1)*y + x2*y1 - y2*x1)
        denominator = np.sqrt((y2-y1)**2 + (x2-x1)**2)
        
        return numerator / denominator if denominator != 0 else 0
    
    def point_side_of_line(self, point, line_point1, line_point2):
        """Determine which side of a line a point is on"""
        x, y = point
        x1, y1 = line_point1
        x2, y2 = line_point2
        
        return ((x2 - x1) * (y - y1) - (y2 - y1) * (x - x1)) > 0
    
    def process_frame(self, frame):
        """Process a single frame for traffic violations"""
        start_time = time.time()
        self.frame_count += 1
        
        # Detect vehicles
        detections, confidences, class_ids = self.detect_vehicles(frame)
        
        # Update tracking
        tracked_objects = self.update_tracking(detections, confidences, class_ids)
        
        # Detect traffic light state
        self.traffic_light_state = self.detect_traffic_light(frame)
        
        # Calculate speeds and check for violations
        for obj_id, obj_data in tracked_objects.items():
            speed = self.calculate_speed(obj_id, obj_data)
            obj_data['speed'] = speed
            
            # Check for speeding
            if speed > self.speed_limit:
                # Only record violation if not recently recorded
                if (obj_data['last_violation'] is None or 
                    (datetime.datetime.now() - obj_data['last_violation']).total_seconds() > 5):
                    
                    # Record speeding violation
                    violation = {
                        'type': 'speeding',
                        'object_id': obj_id,
                        'speed': speed,
                        'timestamp': datetime.datetime.now(),
                        'location': obj_data['centroids'][-1],
                        'vehicle_type': self.get_vehicle_type(obj_data['class_id'])
                    }
                    self.violations.append(violation)
                    self.violation_count['speeding'] += 1
                    obj_data['last_violation'] = datetime.datetime.now()
                    
                    # Draw warning on frame
                    x, y, w, h = obj_data['rect']
                    cv2.rectangle(frame, (x, y), (x+w, y+h), self.colors['violation'], 2)
                    cv2.putText(frame, f"Speeding: {speed:.1f} km/h", 
                               (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.colors['violation'], 2)
            
            # Check for red light violations
            if self.traffic_light_state == "red":
                # Check if vehicle is moving through intersection
                if speed > 10:  # Moving faster than 10 km/h
                    # Only record violation if not recently recorded
                    if (obj_data['last_violation'] is None or 
                        (datetime.datetime.now() - obj_data['last_violation']).total_seconds() > 5):
                        
                        violation = {
                            'type': 'red_light',
                            'object_id': obj_id,
                            'timestamp': datetime.datetime.now(),
                            'location': obj_data['centroids'][-1],
                            'vehicle_type': self.get_vehicle_type(obj_data['class_id'])
                        }
                        self.violations.append(violation)
                        self.violation_count['red_light'] += 1
                        obj_data['last_violation'] = datetime.datetime.now()
                        
                        # Draw warning on frame
                        x, y, w, h = obj_data['rect']
                        cv2.rectangle(frame, (x, y), (x+w, y+h), self.colors['violation'], 2)
                        cv2.putText(frame, "Red Light Violation", 
                                   (x, y-30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.colors['violation'], 2)
            
            # Check for lane violations
            if self.detect_lane_violation(obj_data):
                # Only record violation if not recently recorded
                if (obj_data['last_violation'] is None or 
                    (datetime.datetime.now() - obj_data['last_violation']).total_seconds() > 5):
                    
                    violation = {
                        'type': 'lane_violation',
                        'object_id': obj_id,
                        'timestamp': datetime.datetime.now(),
                        'location': obj_data['centroids'][-1],
                        'vehicle_type': self.get_vehicle_type(obj_data['class_id'])
                    }
                    self.violations.append(violation)
                    self.violation_count['lane_violation'] += 1
                    obj_data['last_violation'] = datetime.datetime.now()
                    
                    # Draw warning on frame
                    x, y, w, h = obj_data['rect']
                    cv2.rectangle(frame, (x, y), (x+w, y+h), self.colors['violation'], 2)
                    cv2.putText(frame, "Lane Violation", 
                               (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.colors['violation'], 2)
            
            # Draw vehicle bounding box and speed
            x, y, w, h = obj_data['rect']
            vehicle_type = self.get_vehicle_type(obj_data['class_id'])
            color = self.colors.get(vehicle_type, (255, 255, 255))
            
            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
            cv2.putText(frame, f"{vehicle_type}: {speed:.1f} km/h", 
                       (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors['speed'], 1)
        
        # Draw traffic light status
        if self.traffic_light_roi:
            x, y, w, h = self.traffic_light_roi
            cv2.rectangle(frame, (x, y), (x+w, y+h), self.colors['traffic_light'], 2)
            cv2.putText(frame, f"Traffic Light: {self.traffic_light_state}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, self.colors['traffic_light'], 2)
        
        # Draw lane boundaries
        for boundary in self.lane_boundaries:
            (x1, y1), (x2, y2) = boundary
            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)
        
        # Draw speed estimation area
        if self.speed_estimation_area is not None:
            cv2.polylines(frame, [np.int32(self.speed_estimation_area)], True, (255, 0, 0), 2)
        
        # Display violation counts
        cv2.putText(frame, f"Speeding: {self.violation_count['speeding']}", 
                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        cv2.putText(frame, f"Red Light: {self.violation_count['red_light']}", 
                   (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        cv2.putText(frame, f"Lane Violations: {self.violation_count['lane_violation']}", 
                   (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # Calculate and display FPS
        processing_time = time.time() - start_time
        self.processing_times.append(processing_time)
        avg_processing_time = np.mean(self.processing_times) if self.processing_times else processing_time
        fps = 1.0 / avg_processing_time if avg_processing_time > 0 else 0
        
        cv2.putText(frame, f"FPS: {fps:.1f}", 
                   (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        return frame
    
    def get_vehicle_type(self, class_id):
        """Map class ID to vehicle type"""
        vehicle_types = {
            2: 'car',
            3: 'motorcycle',
            5: 'bus',
            7: 'truck'
        }
        return vehicle_types.get(class_id, 'unknown')
    
    def save_violations(self, filename="violations.csv"):
        """Save detected violations to a CSV file"""
        if not self.violations:
            print("No violations detected")
            return
            
        df = pd.DataFrame(self.violations)
        df.to_csv(filename, index=False)
        print(f"Violations saved to {filename}")
        print(f"Total violations: {len(self.violations)}")
        print(f"Speeding: {self.violation_count['speeding']}")
        print(f"Red Light: {self.violation_count['red_light']}")
        print(f"Lane Violations: {self.violation_count['lane_violation']}")

# Main function to run the detection
def main():
    # Initialize detector
    detector = EnhancedTrafficViolationDetector()
    
    # For demonstration, we'll use a sample video or webcam
    video_path = "traffic_video.mp4"  # Replace with your video path
    # video_path = 0  # For webcam
    
    cap = cv2.VideoCapture(video_path)
    
    # Get video properties
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    detector.fps = cap.get(cv2.CAP_PROP_FPS)
    
    print(f"Video resolution: {width}x{height}, FPS: {detector.fps}")
    
    # Set speed estimation area (adjust based on your video)
    points = [
        [width * 0.3, height * 0.7],
        [width * 0.7, height * 0.7],
        [width * 0.8, height * 0.9],
        [width * 0.2, height * 0.9]
    ]
    detector.set_speed_estimation_area(points)
    
    # Set traffic light ROI (adjust based on your video)
    traffic_light_roi = (int(width * 0.8), int(height * 0.1), 50, 150)  # x, y, w, h
    detector.set_traffic_light_roi(traffic_light_roi)
    
    # Set lane boundaries (for demonstration)
    lane_boundaries = [
        ((width * 0.3, height * 0.7), (width * 0.3, height * 0.9)),  # Left boundary
        ((width * 0.7, height * 0.7), (width * 0.7, height * 0.9))   # Right boundary
    ]
    detector.set_lane_boundaries(lane_boundaries)
    
    # Create output video writer
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter('output_violations.avi', fourcc, detector.fps, (width, height))
    
    print("Starting traffic violation detection. Press 'q' to quit, 'p' to pause")
    
    paused = False
    while cap.isOpened():
        if not paused:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Process frame for violations
            processed_frame = detector.process_frame(frame)
            
            # Write frame to output video
            out.write(processed_frame)
            
            # Show the frame
            cv2.imshow('Enhanced Traffic Violation Detection', processed_frame)
        
        # Keyboard controls
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('p'):
            paused = not paused
        elif key == ord('s'):
            detector.save_violations()
            
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    
    # Save violations to file
    detector.save_violations()

if __name__ == "__main__":
    main()
